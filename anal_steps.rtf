{\rtf1\ansi\ansicpg1252\cocoartf1504\cocoasubrtf810
{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\froman\fcharset0 Times-Roman;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh9800\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs36 \cf0 Map out road network and coastal outline\
Import data into the model\
Visualise tap in tap out data as heat (segregate by on and off boarding)\
Filter by time of day (10 min time window)\
Approximate total number of commuters on a bus at a single point of time\
Allow filtering by busID\
Estimate bus size by load ceiling\
Estimate full buses\
Visualise routing of full buses\
Identify under serviced stops\
Identify overserviced stops\
Identify under utilised buses
\fs24 \
\
Implement algorithm to propose reallocation of buses\
\
Bonus\
Abstract data to a persistent location. (Spark R)\
Dynamic allocation model based on time of day\
\
\
Procedure:\
- City_nation_ride data contains in excess of a million entries from 15 feb 16 to 21 feb 16, while only a week\'92s worth of data, it is still substantial and may cause issues with the model during testing. As such, we extract a single day\'92s data - 15/2/16 for our testing. (144240 lines)\
- Also, there are numerous rows with faulty columns (4,7,8). (ASSUME? negligible amount. Delete these lines)\
- Need to convert bus stop unique 5 digit. Download SHP bus stop data from LTA data mall. Open SHP file in GQIS. Add attributes $x and $y to data points. Export attribute table as CSV. \
- Download road network shp file. \
- Create server.R and ui.R files for shiny application. outline and bus stop location data into the model.\
-Certain bus codes do not map to any particular XY coords as of the 2016 catalogs. Possibly these stops were / are under construction. We remove these entries. Subsequent entries from the transportation data that correspond to these missing entries will also be removed. This current number seems sufficiently small as to be negligible to the accuracy of the model\
- Transform tito data to csv. Load into model\
- Allow R shiny UI widget selection of date and time (use of package shinyTime for time input). From there, use dyplr filter function to get only entries in the tito dates that correspond to that particular date-time window. allow a +- 2 mins flexibility of dataset and also to open up the window and give greater inset via a larger data observation window. Seconds are ignored.\
- Now we need to count the density at each stop at a particular time window. \
\
\
\
\
\pard\pardeftab720\sl280\partightenfactor0

\f1 \cf2 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 HoustonMap <- ggmap("houston", extent = "device", legend = "topleft") HoustonMap + stat_density2d( aes(x = lon, y = lat, fill = ..level.., alpha = ..level..), size = 2, bins = 4, data = violent_crimes, geom = "polygon")
\f0 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf0 \
}